{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvjaz7e2aoUw",
        "outputId": "a836db7a-4747-4852-c63d-87f537a2fb34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data loaded successfully from 'telemonitoring/parkinsons_updrs.data' inside 'parkinsons.zip'. Shape: (5875, 22)\n",
            "\n",
            "--- Missing Value Count per Column ---\n",
            "Series([], dtype: int64)\n",
            "\n",
            "‚úÖ No duplicate rows found.\n",
            "\n",
            "üßπ Dropped columns: ['subject#']\n",
            "\n",
            "--- Final Cleaned Data Info ---\n",
            "Final Data Shape: (5875, 21)\n",
            "   age  sex  test_time  motor_UPDRS  total_UPDRS  Jitter(%)  Jitter(Abs)  \\\n",
            "0   72    0     5.6431       28.199       34.398    0.00662     0.000034   \n",
            "1   72    0    12.6660       28.447       34.894    0.00300     0.000017   \n",
            "2   72    0    19.6810       28.695       35.389    0.00481     0.000025   \n",
            "3   72    0    25.6470       28.905       35.810    0.00528     0.000027   \n",
            "4   72    0    33.6420       29.187       36.375    0.00335     0.000020   \n",
            "\n",
            "   Jitter:RAP  Jitter:PPQ5  Jitter:DDP  ...  Shimmer(dB)  Shimmer:APQ3  \\\n",
            "0     0.00401      0.00317     0.01204  ...        0.230       0.01438   \n",
            "1     0.00132      0.00150     0.00395  ...        0.179       0.00994   \n",
            "2     0.00205      0.00208     0.00616  ...        0.181       0.00734   \n",
            "3     0.00191      0.00264     0.00573  ...        0.327       0.01106   \n",
            "4     0.00093      0.00130     0.00278  ...        0.176       0.00679   \n",
            "\n",
            "   Shimmer:APQ5  Shimmer:APQ11  Shimmer:DDA       NHR     HNR     RPDE  \\\n",
            "0       0.01309        0.01662      0.04314  0.014290  21.640  0.41888   \n",
            "1       0.01072        0.01689      0.02982  0.011112  27.183  0.43493   \n",
            "2       0.00844        0.01458      0.02202  0.020220  23.047  0.46222   \n",
            "3       0.01265        0.01963      0.03317  0.027837  24.445  0.48730   \n",
            "4       0.00929        0.01819      0.02036  0.011625  26.126  0.47188   \n",
            "\n",
            "       DFA      PPE  \n",
            "0  0.54842  0.16006  \n",
            "1  0.56477  0.10810  \n",
            "2  0.54405  0.21014  \n",
            "3  0.57794  0.33277  \n",
            "4  0.56122  0.19361  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "üéâ Data cleaning and loading is complete! The dataset is now in the 'df_cleaned' DataFrame.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import io # Used to read data from the zip file object\n",
        "\n",
        "# --- 1. Corrected File Path and Archive Name ---\n",
        "# The original file name is 'parkinsons.zip'.\n",
        "# The nested CSV file path *within* the archive is:\n",
        "# 'telemonitoring/parkinsons_updrs.data'\n",
        "\n",
        "zip_file_name = 'parkinsons.zip'\n",
        "nested_file_path = 'telemonitoring/parkinsons_updrs.data'\n",
        "\n",
        "# --- 2. Load the Dataset Safely from the ZIP Archive ---\n",
        "try:\n",
        "    # 1. Open the zip file\n",
        "    with zipfile.ZipFile(zip_file_name, 'r') as z:\n",
        "        # 2. Open the nested file within the archive\n",
        "        # The 'io.BytesIO' object allows pandas to read the file contents directly\n",
        "        # from memory without extracting the file to disk first.\n",
        "        with z.open(nested_file_path) as f:\n",
        "            # 3. Read the file content directly into a DataFrame\n",
        "            # The file is correctly read as a CSV since its contents are comma-separated.\n",
        "            df = pd.read_csv(f)\n",
        "\n",
        "    print(f\"‚úÖ Data loaded successfully from '{nested_file_path}' inside '{zip_file_name}'. Shape: {df.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Zip file '{zip_file_name}' not found. Check if the file was uploaded to the correct location.\")\n",
        "except KeyError:\n",
        "    print(f\"‚ùå ERROR: CSV file '{nested_file_path}' not found inside '{zip_file_name}'. Check the exact file path inside the zip.\")\n",
        "    df = None\n",
        "\n",
        "if df is not None:\n",
        "    # ------------------------------------------------------------\n",
        "    # --- 3. Initial Data Cleaning and Preparation (as requested) ---\n",
        "    # ------------------------------------------------------------\n",
        "\n",
        "    # Check for missing values (Nulls)\n",
        "    print(\"\\n--- Missing Value Count per Column ---\")\n",
        "    missing_values = df.isnull().sum()\n",
        "    print(missing_values[missing_values > 0])\n",
        "    # The original dataset info suggests no missing values, but checking is always good practice.\n",
        "\n",
        "    # Check for and Remove Duplicate Rows\n",
        "    duplicate_rows = df.duplicated().sum()\n",
        "    if duplicate_rows > 0:\n",
        "        print(f\"\\nüóëÔ∏è Found {duplicate_rows} duplicate rows. Removing...\")\n",
        "        df.drop_duplicates(inplace=True)\n",
        "        print(f\"New data shape after removing duplicates: {df.shape}\")\n",
        "    else:\n",
        "        print(\"\\n‚úÖ No duplicate rows found.\")\n",
        "\n",
        "    # Drop the 'subject#' column as it's an identifier and not typically used for training\n",
        "    columns_to_drop = ['subject#']\n",
        "    if all(col in df.columns for col in columns_to_drop):\n",
        "        df_cleaned = df.drop(columns=columns_to_drop)\n",
        "        print(f\"\\nüßπ Dropped columns: {columns_to_drop}\")\n",
        "    else:\n",
        "        df_cleaned = df\n",
        "        print(\"\\nNote: Columns to drop were not found; no columns were dropped.\")\n",
        "\n",
        "    # --- 4. Final Data Summary ---\n",
        "    print(\"\\n--- Final Cleaned Data Info ---\")\n",
        "    print(f\"Final Data Shape: {df_cleaned.shape}\")\n",
        "    print(df_cleaned.head())\n",
        "\n",
        "    print(\"\\nüéâ Data cleaning and loading is complete! The dataset is now in the 'df_cleaned' DataFrame.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the 'df_cleaned' DataFrame from the previous step is available\n",
        "\n",
        "# --- 1. Feature (X) and Target (y) Separation ---\n",
        "# The goal is typically to predict one of the UPDRS scores.\n",
        "# Let's choose 'total_UPDRS' as the target variable (y).\n",
        "\n",
        "target_column = 'total_UPDRS'\n",
        "features = df_cleaned.drop(columns=[target_column, 'motor_UPDRS'])\n",
        "# Drop the target and the other highly correlated UPDRS score\n",
        "# to make the prediction task more meaningful/challenging for the ML model.\n",
        "\n",
        "X = features\n",
        "y = df_cleaned[target_column]\n",
        "\n",
        "print(f\"\\n‚úÖ Target Variable (y): '{target_column}'\")\n",
        "print(f\"Features (X) shape: {X.shape}\")\n",
        "print(f\"Target (y) shape: {y.shape}\")\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# --- 2. Quick Exploratory Data Analysis (EDA) ---\n",
        "# Check the distribution and correlation of variables.\n",
        "\n",
        "print(\"\\n--- Summary Statistics of Features ---\")\n",
        "print(X.describe().T)\n",
        "\n",
        "# Optional: Check correlation with the target (uncomment if needed)\n",
        "# print(\"\\n--- Top 5 Features Correlated with total_UPDRS ---\")\n",
        "# print(df_cleaned.corr()[target_column].sort_values(ascending=False).head(6))\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# --- 3. Feature Scaling (Standardization) ---\n",
        "# Most ML algorithms perform better when numerical input features are scaled.\n",
        "# We will use StandardScaler to center the data around 0 with a unit standard deviation.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"\\n‚öôÔ∏è Applying Feature Scaling (Standardization)...\")\n",
        "\n",
        "# Initialize the Scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the features and transform the data\n",
        "X_scaled_array = scaler.fit_transform(X)\n",
        "\n",
        "# Convert the scaled array back into a DataFrame for easier viewing/handling\n",
        "X_scaled = pd.DataFrame(X_scaled_array, columns=X.columns)\n",
        "\n",
        "print(\"Scaled features head:\")\n",
        "print(X_scaled.head())\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# --- 4. Train-Test Split ---\n",
        "# This step is crucial to prevent **overfitting**. We reserve a portion of the data\n",
        "# for evaluation after the model has been trained.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, # Use the scaled features!\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42 # Set a random state for reproducibility\n",
        ")\n",
        "\n",
        "print(\"\\n--- Final Data Split Status ---\")\n",
        "print(f\"X_train shape: {X_train.shape} (80% for training)\")\n",
        "print(f\"X_test shape:  {X_test.shape} (20% for testing)\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape:  {y_test.shape}\")\n",
        "\n",
        "print(\"\\nüéâ Data preparation is complete! You are now ready for model training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMCh7zlVcbVT",
        "outputId": "a48df8d1-a552-40de-a76f-9122ac2bc989"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Target Variable (y): 'total_UPDRS'\n",
            "Features (X) shape: (5875, 19)\n",
            "Target (y) shape: (5875,)\n",
            "\n",
            "--- Summary Statistics of Features ---\n",
            "                count       mean        std        min        25%        50%  \\\n",
            "age            5875.0  64.804936   8.821524  36.000000  58.000000  65.000000   \n",
            "sex            5875.0   0.317787   0.465656   0.000000   0.000000   0.000000   \n",
            "test_time      5875.0  92.863722  53.445602  -4.262500  46.847500  91.523000   \n",
            "Jitter(%)      5875.0   0.006154   0.005624   0.000830   0.003580   0.004900   \n",
            "Jitter(Abs)    5875.0   0.000044   0.000036   0.000002   0.000022   0.000035   \n",
            "Jitter:RAP     5875.0   0.002987   0.003124   0.000330   0.001580   0.002250   \n",
            "Jitter:PPQ5    5875.0   0.003277   0.003732   0.000430   0.001820   0.002490   \n",
            "Jitter:DDP     5875.0   0.008962   0.009371   0.000980   0.004730   0.006750   \n",
            "Shimmer        5875.0   0.034035   0.025835   0.003060   0.019120   0.027510   \n",
            "Shimmer(dB)    5875.0   0.310960   0.230254   0.026000   0.175000   0.253000   \n",
            "Shimmer:APQ3   5875.0   0.017156   0.013237   0.001610   0.009280   0.013700   \n",
            "Shimmer:APQ5   5875.0   0.020144   0.016664   0.001940   0.010790   0.015940   \n",
            "Shimmer:APQ11  5875.0   0.027481   0.019986   0.002490   0.015665   0.022710   \n",
            "Shimmer:DDA    5875.0   0.051467   0.039711   0.004840   0.027830   0.041110   \n",
            "NHR            5875.0   0.032120   0.059692   0.000286   0.010955   0.018448   \n",
            "HNR            5875.0  21.679495   4.291096   1.659000  19.406000  21.920000   \n",
            "RPDE           5875.0   0.541473   0.100986   0.151020   0.469785   0.542250   \n",
            "DFA            5875.0   0.653240   0.070902   0.514040   0.596180   0.643600   \n",
            "PPE            5875.0   0.219589   0.091498   0.021983   0.156340   0.205500   \n",
            "\n",
            "                      75%         max  \n",
            "age             72.000000   85.000000  \n",
            "sex              1.000000    1.000000  \n",
            "test_time      138.445000  215.490000  \n",
            "Jitter(%)        0.006800    0.099990  \n",
            "Jitter(Abs)      0.000053    0.000446  \n",
            "Jitter:RAP       0.003290    0.057540  \n",
            "Jitter:PPQ5      0.003460    0.069560  \n",
            "Jitter:DDP       0.009870    0.172630  \n",
            "Shimmer          0.039750    0.268630  \n",
            "Shimmer(dB)      0.365000    2.107000  \n",
            "Shimmer:APQ3     0.020575    0.162670  \n",
            "Shimmer:APQ5     0.023755    0.167020  \n",
            "Shimmer:APQ11    0.032715    0.275460  \n",
            "Shimmer:DDA      0.061735    0.488020  \n",
            "NHR              0.031463    0.748260  \n",
            "HNR             24.444000   37.875000  \n",
            "RPDE             0.614045    0.966080  \n",
            "DFA              0.711335    0.865600  \n",
            "PPE              0.264490    0.731730  \n",
            "\n",
            "‚öôÔ∏è Applying Feature Scaling (Standardization)...\n",
            "Scaled features head:\n",
            "        age       sex  test_time  Jitter(%)  Jitter(Abs)  Jitter:RAP  \\\n",
            "0  0.815695 -0.682509  -1.632090   0.082905    -0.284242    0.327453   \n",
            "1  0.815695 -0.682509  -1.500676  -0.560793    -0.756723   -0.533746   \n",
            "2  0.815695 -0.682509  -1.369410  -0.238944    -0.539382   -0.300038   \n",
            "3  0.815695 -0.682509  -1.257773  -0.155370    -0.485186   -0.344859   \n",
            "4  0.815695 -0.682509  -1.108169  -0.498557    -0.663894   -0.658604   \n",
            "\n",
            "   Jitter:PPQ5  Jitter:DDP   Shimmer  Shimmer(dB)  Shimmer:APQ3  Shimmer:APQ5  \\\n",
            "0    -0.028637    0.328505 -0.324594    -0.351642     -0.209709     -0.423356   \n",
            "1    -0.476212   -0.534825 -0.534016    -0.573156     -0.545158     -0.565592   \n",
            "2    -0.320767   -0.298983 -0.669115    -0.564469     -0.741592     -0.702426   \n",
            "3    -0.170682   -0.344871 -0.423692     0.069668     -0.460540     -0.449763   \n",
            "4    -0.529814   -0.659682 -0.658276    -0.586186     -0.783145     -0.651413   \n",
            "\n",
            "   Shimmer:APQ11  Shimmer:DDA       NHR       HNR      RPDE       DFA  \\\n",
            "0      -0.543466    -0.209704 -0.298721 -0.009205 -1.214066 -1.478500   \n",
            "1      -0.529955    -0.545153 -0.351965  1.282650 -1.055119 -1.247880   \n",
            "2      -0.645545    -0.741587 -0.199370  0.318711 -0.784860 -1.540139   \n",
            "3      -0.392849    -0.460787 -0.071754  0.644530 -0.536487 -1.062115   \n",
            "4      -0.464905    -0.783392 -0.343370  1.036305 -0.689195 -1.297953   \n",
            "\n",
            "        PPE  \n",
            "0 -0.650658  \n",
            "1 -1.218585  \n",
            "2 -0.103280  \n",
            "3  1.237075  \n",
            "4 -0.283954  \n",
            "\n",
            "--- Final Data Split Status ---\n",
            "X_train shape: (4700, 19) (80% for training)\n",
            "X_test shape:  (1175, 19) (20% for testing)\n",
            "y_train shape: (4700,)\n",
            "y_test shape:  (1175,)\n",
            "\n",
            "üéâ Data preparation is complete! You are now ready for model training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Model Training and Evaluation ---\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Initialize the Model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "print(\"\\nüöÄ Training Random Forest Regressor...\")\n",
        "# Train the Model\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Make Predictions on the Test Set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the Model Performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse) # Root Mean Squared Error (RMSE) is more interpretable\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- Model Evaluation ---\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} (Prediction error in UPDRS units)\")\n",
        "print(f\"R-squared Score (R¬≤): {r2:.4f} (Closer to 1.0 is better)\")\n",
        "\n",
        "print(\"\\nFinishing touch: Displaying Feature Importance\")\n",
        "# Show which features the model found most important\n",
        "feature_importance = pd.Series(model.feature_importances_, index=X_train.columns)\n",
        "print(feature_importance.sort_values(ascending=False).head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNUUupOAccKP",
        "outputId": "045e9fb5-2f3c-47ca-8343-af3c804b22c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Training Random Forest Regressor...\n",
            "Training complete.\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Mean Squared Error (MSE): 2.57\n",
            "Root Mean Squared Error (RMSE): 1.60 (Prediction error in UPDRS units)\n",
            "R-squared Score (R¬≤): 0.9768 (Closer to 1.0 is better)\n",
            "\n",
            "Finishing touch: Displaying Feature Importance\n",
            "age          0.639437\n",
            "sex          0.088428\n",
            "DFA          0.087588\n",
            "test_time    0.067830\n",
            "HNR          0.032121\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import io\n",
        "import joblib # Required for saving the model/scaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from google.colab import files # Required for downloading files\n",
        "\n",
        "# --- A. Data Loading and Cleaning ---\n",
        "print(\"--- A. Data Loading and Cleaning ---\")\n",
        "zip_file_name = 'parkinsons.zip'\n",
        "nested_file_path = 'telemonitoring/parkinsons_updrs.data'\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_name, 'r') as z:\n",
        "        with z.open(nested_file_path) as f:\n",
        "            df = pd.read_csv(f)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    df = None\n",
        "\n",
        "if df is not None:\n",
        "    # Remove duplicates\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    # Drop identifier column\n",
        "    df_cleaned = df.drop(columns=['subject#'])\n",
        "\n",
        "    # --- B. Data Preparation ---\n",
        "    print(\"--- B. Data Preparation ---\")\n",
        "    target_column = 'total_UPDRS'\n",
        "    features = df_cleaned.drop(columns=[target_column, 'motor_UPDRS'])\n",
        "\n",
        "    X = features\n",
        "    y = df_cleaned[target_column]\n",
        "\n",
        "    # Feature Scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled_array = scaler.fit_transform(X)\n",
        "    X_scaled = pd.DataFrame(X_scaled_array, columns=X.columns)\n",
        "\n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled,\n",
        "        y,\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # --- C. Hyperparameter Tuning and Training ---\n",
        "    print(\"--- C. Hyperparameter Tuning and Training ---\")\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100],\n",
        "        'max_depth': [10, 20],\n",
        "        'min_samples_split': [5, 10]\n",
        "    }\n",
        "\n",
        "    rf = RandomForestRegressor(random_state=42)\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=rf,\n",
        "        param_grid=param_grid,\n",
        "        cv=3,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        verbose=0,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = np.sqrt(-grid_search.best_score_)\n",
        "\n",
        "    print(f\"Best Parameters Found: {best_params}\")\n",
        "    print(f\"Best CV RMSE: {best_score:.2f}\")\n",
        "\n",
        "    # Retrain the Final Production Model on ALL scaled data\n",
        "    X_all = X_scaled\n",
        "    y_all = y\n",
        "\n",
        "    # *** This is where 'final_model' is defined! ***\n",
        "    final_model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "    final_model.fit(X_all, y_all)\n",
        "    print(\"‚úÖ Final Model Training Complete on ALL Data.\")\n",
        "\n",
        "    # --- D. Save and Download Files ---\n",
        "    print(\"\\n--- D. Save and Download Files ---\")\n",
        "\n",
        "    # 1. Save the Trained Model\n",
        "    model_filename = 'final_parkinsons_regressor.pkl'\n",
        "    joblib.dump(final_model, model_filename)\n",
        "\n",
        "    # 2. Save the Scaler\n",
        "    scaler_filename = 'parkinsons_scaler.pkl'\n",
        "    joblib.dump(scaler, scaler_filename)\n",
        "\n",
        "    print(f\"‚úÖ Model saved as: {model_filename}\")\n",
        "    print(f\"‚úÖ Scaler saved as: {scaler_filename}\")\n",
        "\n",
        "    # 3. Prompt Download\n",
        "    print(\"\\nüöÄ Preparing files for download...\")\n",
        "    files.download(model_filename)\n",
        "    files.download(scaler_filename)\n",
        "    print(\"üéâ Two files should now be downloading to your local machine.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nCannot proceed with saving due to data loading error in section A.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "ZjjV-hVRds8r",
        "outputId": "b48e709c-abc5-4eff-e698-0118989ccfd0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- A. Data Loading and Cleaning ---\n",
            "--- B. Data Preparation ---\n",
            "--- C. Hyperparameter Tuning and Training ---\n",
            "Best Parameters Found: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Best CV RMSE: 2.15\n",
            "‚úÖ Final Model Training Complete on ALL Data.\n",
            "\n",
            "--- D. Save and Download Files ---\n",
            "‚úÖ Model saved as: final_parkinsons_regressor.pkl\n",
            "‚úÖ Scaler saved as: parkinsons_scaler.pkl\n",
            "\n",
            "üöÄ Preparing files for download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_69254f55-cdd0-4718-b66b-b7cef4328a32\", \"final_parkinsons_regressor.pkl\", 17433505)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_40a798eb-e28f-4314-ad01-ad7d521b32ed\", \"parkinsons_scaler.pkl\", 1503)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéâ Two files should now be downloading to your local machine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FcEXFEREfb4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ys4WHXquhKLO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n9PV6Bn8hLnO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}